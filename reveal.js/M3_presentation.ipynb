{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>Predicting your geological sample\n",
    "## <center>using CNN\n",
    "<center><img src=\"0.pics/deep_learning_2.jpg\"/></center>  \n",
    "\n",
    "### <center> Ionel ≈ûcheul        \n",
    "### <center> Spiced Academy Graduation, 09.08.2022     \n",
    " <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Things you should know about me:\n",
    "#### Geoscience Background ‚õ∞Ô∏èüåã‚öí\n",
    "#### Big Fan of Travelling & Rocks ‚úàÔ∏èüöÇüåç \n",
    "#### Spiced Academy Graduate in TWO HOURS!  ü•≥ü•≥ü•≥\n",
    "![ME](0.pics/me2.6.png)\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "&nbsp;\n",
    " <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "&nbsp;\n",
    "### - Goals\n",
    "### - Workflow & Tools\n",
    "### - Data Available\n",
    "### - Results & Demo\n",
    "### - Way forward\n",
    "\n",
    "\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "####  <font color='blue'>Goals</font>$\\rightarrow$ Workflow & Tools$\\rightarrow$Data Available$\\rightarrow$ Results & Demo$\\rightarrow$ Way forward\n",
    " <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why this project? \n",
    "## It all started when I heard...\n",
    "![The Rock](0.pics/rock3.png)\n",
    "\n",
    "<br/><br/>\n",
    "<br/>\n",
    "####  <font color='blue'>Goals</font>$\\rightarrow$ Workflow & Tools$\\rightarrow$Data Available$\\rightarrow$ Results & Demo$\\rightarrow$ Way forward\n",
    " <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coming back to the serious business:\n",
    "\n",
    "$\\;\\;\\;\\;\\;\\;$\n",
    "### 1. Can Deep Learning be used for this classification?\n",
    "<br/><br/>\n",
    "\n",
    "### 2. Does it work?\n",
    "<br/><br/>\n",
    "\n",
    "### 3. How quick can we get some results?\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/>\n",
    "\n",
    "####  <font color='blue'>Goals</font>$\\rightarrow$ Workflow & Tools$\\rightarrow$Data Available$\\rightarrow$ Results & Demo$\\rightarrow$ Way forward\n",
    " <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modules used\n",
    "![Deep Learning](0.pics/modules_used.png)\n",
    "\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "####  Goals$\\rightarrow$ <font color='blue'> Workflow & Tools</font>$\\rightarrow$Data Available$\\rightarrow$ Results & Demo$\\rightarrow$ Way forward\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Workflow \n",
    "\n",
    "![Deep Learning](0.pics/CNN_sketch_modified.png)\n",
    "\n",
    "#### Goals$\\rightarrow$ <font color='blue'> Workflow & Tools</font>$\\rightarrow$Data Available$\\rightarrow$ Results & Demo$\\rightarrow$ Way forward\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Available\n",
    "#### - 1000 pictures*, 200 for each category\n",
    "#### - 5 Categories: `amethyst`,  `ammonite`,  `aventurin`,  `empty`,  `obsidian`\n",
    "![Labels](0.pics/labels+text2.png)\n",
    "<br/>\n",
    "#### Goals$\\rightarrow$  Workflow & Tools$\\rightarrow$ <font color='blue'>Data Available</font> $\\rightarrow$ Results & Demo$\\rightarrow$ Way forward\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## RESULTS\n",
    "#### Final loss: 0.23  /  Final accuracy: 0.95\n",
    "![Labels](0.pics/accuracy_results_90.png)\n",
    "<br/>\n",
    "####  Goals$\\rightarrow$Workflow & Tools$\\rightarrow$Data Available$\\rightarrow$ <font color='blue'> Results & Demo</font>$\\rightarrow$ Way forward\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## DEMO TIME        \n",
    "![Streamlit](0.pics/streamlit.png)\n",
    "\n",
    "   APP [**HERE**](http://localhost:8501/)\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "####  Goals$\\rightarrow$Workflow & Tools$\\rightarrow$Data Available$\\rightarrow$ <font color='blue'> Results & Demo</font>$\\rightarrow$ Way forward\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Way forward\n",
    "\n",
    "![Streamlit](0.pics/wf3.png)\n",
    "<br/>\n",
    "<br/>\n",
    "#### Goals$\\rightarrow$ Workflow & Tools$\\rightarrow$Data Available$\\rightarrow$ Results & Demo$\\rightarrow$ <font color='blue'> Way forward</font>\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A big thank you  to everyone:\n",
    "<br/>\n",
    "\n",
    "#### The Teachers: @Paula, @Joseph, @Anastasia, @Carmine, @Ugur, @Sara, @Arjun, @Samuel, @Lindsay, @Olga, and all the other collaborators\n",
    "<br/><br/>\n",
    "#### My Colleagues: @Arita, @Nadine, @Rashmi, @Alex, @Erkam, @Johannes, @Michael, @Omid\n",
    "\n",
    "<br/><br/>\n",
    "### Last but not least: My amazing partner @Alice for supporting me during all these 3 intense months\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/>\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "![the_end](0.pics/the_end.png)\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## For those of you who might have found this presentation too tough...\n",
    "\n",
    "![the_end](0.pics/book_recommendation.png)\n",
    "<br/><br/>\n",
    "<br/>\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional slides\n",
    "\n",
    "\n",
    "### Why MobileNetV2?\n",
    "- Quick, easy and gives good results\n",
    "- Has over 3.4 million parameters\n",
    "- The MobileNetV2 Overall Architecture\n",
    "- The primary network (width multiplier 1, 224√ó224), has a computational cost of 300 million multiply-adds\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "\n",
    "\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional slides\n",
    "\n",
    "\n",
    "### Workflow details\n",
    "\n",
    "\n",
    "METHOD 2\n",
    "1. Take the weights and architecture of a [pre-trained network](https://keras.io/api/applications/) (e.g MobileNetV2, ResNEt-50) \n",
    "2. Load the \"convolutional base\" of the model (use all **BUT** the dense layers)\n",
    "3. Freeze all the layers of the base\n",
    "4. Add a fully connected dense layer on top\n",
    "5. **Add a task specific dense output layer**\n",
    "6. Compile and fit the model to your data\n",
    "<br/><br/>\n",
    "*taking features learned on one problem, and leveraging them on a new, similar problem. \n",
    "E.g. features from a model that has learned to identify fruits may be useful to kick-start a model meant to identify minerals.\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional slides\n",
    "### Model's summary\n",
    "![model_summary](0.pics/model1+2.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional slides\n",
    "\n",
    "### Resources\n",
    "\n",
    "- ‚í∏ Spiced Academy Learning Material\n",
    "- https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/><br/>\n",
    "<br/>\n",
    "\n",
    "\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Additional slides\n",
    "\n",
    "## More ideas to explore (way forward)\n",
    "\n",
    "### Basic\n",
    "1. Hyperparameters tunning\n",
    "\n",
    "2. Add complexity to the model (increase the number of categories)\n",
    "\n",
    "3. Test other pre-trained models (e.g. ResNEt-50- ~20Mil, VGG16- ~40Mil)\n",
    "\n",
    "### Advanced\n",
    "\n",
    "4. Add a webcam `predict_frame` function \n",
    "5. Implement a `FLASK app`\n",
    "\n",
    "<br/><br/>\n",
    "<br/>\n",
    "#### Goals$\\rightarrow$ Workflow & Tools$\\rightarrow$Data Available$\\rightarrow$ Results & Demo$\\rightarrow$ <font color='blue'> Way forward</font>\n",
    "  <div style=\"text-align: right\"> Copyright ‚í∏ 2022 Ionel Scheul </div>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "deep_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
